<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Agora Video Call with Gestures</title>

  <!-- Agora SDK -->
  <script src="https://download.agora.io/sdk/release/AgoraRTC_N.js"></script>

  <!-- TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>

  <!-- MediaPipe Hands -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

  <style>
    body {
      margin: 0;
      font-family: Arial, sans-serif;
      background: #121212;
      color: white;
      text-align: center;
    }
    #video-container {
      display: flex;
      flex-wrap: wrap;
      justify-content: center;
      gap: 10px;
      height: 85vh;
    }
    .video-box {
      width: 45%;
      height: 40vh;
      background: black;
      border-radius: 10px;
      position: relative;
      overflow: hidden;
    }
    video {
      width: 100%;
      height: 100%;
      object-fit: cover;
    }
    #controls {
      display: flex;
      justify-content: center;
      gap: 10px;
      margin: 20px;
    }
    button {
      padding: 10px 20px;
      font-size: 16px;
      background: #007bff;
      border: none;
      color: white;
      border-radius: 5px;
      cursor: pointer;
    }
    button:hover {
      background: #0056b3;
    }
    #leaveBtn {
      background: red;
    }
    .prediction-box {
      position: absolute;
      bottom: 10px;
      left: 50%;
      transform: translateX(-50%);
      background: rgba(0, 0, 0, 0.5);
      padding: 6px 10px;
      border-radius: 5px;
    }
  </style>
</head>
<body>
  <h1>Agora + Gesture Recognition</h1>

  <div id="video-container"></div>

  <div id="controls">
    <button onclick="joinCall()">Join Call</button>
    <button id="leaveBtn" onclick="leaveCall()">Leave Call</button>
  </div>

  <script>
    const APP_ID = "0f3fde8ae17c4048bcfc8d69286bc851";
    const CHANNEL_NAME = "test";
    const TOKEN = null;

    let client, localVideoTrack, localAudioTrack, camera;
    let model, labels = [];

    // Load gesture model & labels
    async function loadGestureModel() {
      model = await tf.loadLayersModel("model/model.json");
      const res = await fetch("model/labels.json");
      labels = await res.json();
    }

    async function joinCall() {
      await loadGestureModel();

      client = AgoraRTC.createClient({ mode: "rtc", codec: "vp8" });
      await client.join(APP_ID, CHANNEL_NAME, TOKEN, null);

      localVideoTrack = await AgoraRTC.createCameraVideoTrack();
      localAudioTrack = await AgoraRTC.createMicrophoneAudioTrack();

      addUserVideo("local-user", localVideoTrack);

      await client.publish([localVideoTrack, localAudioTrack]);

      client.on("user-published", async (user, mediaType) => {
        await client.subscribe(user, mediaType);
        if (mediaType === "video") {
          addUserVideo(user.uid, user.videoTrack);
          user.videoTrack.play(document.getElementById(`user-${user.uid}`));
        }
        if (mediaType === "audio") {
          user.audioTrack.play();
        }
      });

      client.on("user-unpublished", (user) => {
        removeUserVideo(user.uid);
      });
    }

    function leaveCall() {
      if (localVideoTrack) localVideoTrack.stop(), localVideoTrack.close();
      if (localAudioTrack) localAudioTrack.stop(), localAudioTrack.close();
      client.leave();
      document.getElementById("video-container").innerHTML = "";
    }

    function addUserVideo(userId, track) {
      const container = document.createElement("div");
      container.id = `user-${userId}`;
      container.className = "video-box";

      const videoElement = document.createElement("video");
      videoElement.autoplay = true;
      videoElement.muted = true;
      container.appendChild(videoElement);

      const predictionBox = document.createElement("div");
      predictionBox.className = "prediction-box";
      predictionBox.innerText = "Waiting...";
      container.appendChild(predictionBox);

      document.getElementById("video-container").appendChild(container);

      track.play(videoElement);

      if (userId === "local-user") {
        startGestureDetection(videoElement, predictionBox);
      }
    }

    function removeUserVideo(userId) {
      const container = document.getElementById(`user-${userId}`);
      if (container) container.remove();
    }

    function startGestureDetection(videoEl, outputEl) {
      const hands = new Hands({
        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
      });

      hands.setOptions({
        maxNumHands: 1,
        modelComplexity: 1,
        minDetectionConfidence: 0.8,
        minTrackingConfidence: 0.5
      });

      hands.onResults((results) => {
        if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
          const landmarks = results.multiHandLandmarks[0].flatMap(p => [p.x, p.y, p.z]);
          const input = tf.tensor([landmarks]);
          const prediction = model.predict(input);
          const predictedIndex = prediction.argMax(-1).dataSync()[0];
          const confidence = prediction.dataSync()[predictedIndex];

          if (confidence > 0.7) {
            outputEl.innerText = `Gesture: ${labels[predictedIndex]}`;
          } else {
            outputEl.innerText = "Gesture: Unknown";
          }

          input.dispose();
          prediction.dispose();
        } else {
          outputEl.innerText = "Gesture: -";
        }
      });

      const cam = new Camera(videoEl, {
        onFrame: async () => {
          await hands.send({ image: videoEl });
        },
        width: 640,
        height: 480
      });
      cam.start();
    }
  </script>
</body>
</html>
